{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tempfile\n",
    "import imutils\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('test.jpg',1)\n",
    "#image = image.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(937, 1158, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n"
     ]
    }
   ],
   "source": [
    "# this piece of code works if the text, say, located on the white that lies on the black table\n",
    "# otherwise screenCnt remains None\n",
    "# on the input the colord picture is given\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "edged = cv2.Canny(gray, 10, 50)\n",
    "cnts = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = cnts[0] if imutils.is_cv2() else cnts[1]\n",
    "cnts = sorted(cnts, key=cv2.contourArea, reverse=True)[:5]\n",
    "#print(cnts.shape)\n",
    "\n",
    "screenCnt = None\n",
    "for c in cnts:\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "    if len(approx) == 4:\n",
    "        screenCnt = approx\n",
    "        print('break')\n",
    "        break\n",
    "\n",
    "im1 = Image.open(r'test_cv.jpg', mode='r')\n",
    "#im1 = Image.fromarray(edged)\n",
    "im1 = Image.fromarray(cv2.drawContours(image, [screenCnt], -1, (0, 255, 0), 2))\n",
    "im1.save('test_cv.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one batch of funcitons to rotate the image with any rotation\n",
    "\n",
    "def order_points(pts):\n",
    "    # initialzie a list of coordinates that will be ordered\n",
    "    # such that the first entry in the list is the top-left,\n",
    "    # the second entry is the top-right, the third is the\n",
    "    # bottom-right, and the fourth is the bottom-left\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "\n",
    "    # the top-left point will have the smallest sum, whereas\n",
    "    # the bottom-right point will have the largest sum\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "\n",
    "    # now, compute the difference between the points, the\n",
    "    # top-right point will have the smallest difference,\n",
    "    # whereas the bottom-left will have the largest difference\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "\n",
    "    # return the ordered coordinates\n",
    "    return rect\n",
    "\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "    # obtain a consistent order of the points and unpack them\n",
    "    # individually\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "\n",
    "    # compute the width of the new image, which will be the\n",
    "    # maximum distance between bottom-right and bottom-left\n",
    "    # x-coordiates or the top-right and top-left x-coordinates\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    # compute the height of the new image, which will be the\n",
    "    # maximum distance between the top-right and bottom-right\n",
    "    # y-coordinates or the top-left and bottom-left y-coordinates\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "    # now that we have the dimensions of the new image, construct\n",
    "    # the set of destination points to obtain a \"birds eye view\",\n",
    "    # (i.e. top-down view) of the image, again specifying points\n",
    "    # in the top-left, top-right, bottom-right, and bottom-left\n",
    "    # order\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype=\"float32\")\n",
    "\n",
    "    # compute the perspective transform matrix and then apply it\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second approach to rotate an image\n",
    "# doesn't work correctly. Possibly, it works with angels multiples 45 \n",
    "def rotate(img):\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_img = cv2.bitwise_not(gray_img)\n",
    "    coordinates = np.column_stack(np.where(gray_img > 0))\n",
    "    ang = cv2.minAreaRect(coordinates)[-1]\n",
    "    print(ang)\n",
    "    if ang < -45: \n",
    "        ang = -(90 + ang)\n",
    "    else:\n",
    "        ang = -ang\n",
    "    height, width = img.shape[:2]\n",
    "\n",
    "    center_img = (width / 2, height / 2)\n",
    "\n",
    "    rotationMatrix = cv2.getRotationMatrix2D(center_img, ang, 1.0)\n",
    "\n",
    "    rotated_img = cv2.warpAffine(img, rotationMatrix, (width, height), borderMode = cv2.BORDER_REFLECT)\n",
    "    return rotated_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-90.0\n"
     ]
    }
   ],
   "source": [
    "rotated = rotate(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = Image.open(r'test_cv.jpg', mode='r')\n",
    "im1 = Image.fromarray(rotated)\n",
    "im1.save('test_cv.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise_and_smooth(img):\n",
    "    # input should be grayscale image\n",
    "    filtered = cv2.adaptiveThreshold(img.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 9, 41)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    opening = cv2.morphologyEx(filtered, cv2.MORPH_OPEN, kernel)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "    # bluring (it can be as you wish. See the doc)\n",
    "    img = cv2.GaussianBlur(img,(3,3),0)\n",
    "    or_image = cv2.bitwise_or(img, closing)\n",
    "    return or_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotate image\n",
    "ratio = 1\n",
    "pts = np.array(screenCnt.reshape(4, 2) * ratio)\n",
    "warped = four_point_transform(image, pts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = Image.open(r'test_cv.jpg', mode='r')\n",
    "im1 = Image.fromarray(warped)\n",
    "im1.save('test_cv.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_noise = remove_noise_and_smooth(cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sharp the image\n",
    "kernel_sharpening = np.array([[-1,-1,-1], \n",
    "                              [-1, 8,-1],\n",
    "                              [-1,-1,-1]])\n",
    "\n",
    "sharpened = cv2.filter2D(smooth, -1, kernel_sharpening)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another sharp (or not)\n",
    "blur = cv2.GaussianBlur(removed_noise,(3,3),0)\n",
    "smooth = cv2.addWeighted(blur,1.5,removed_noise,-0.5,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = Image.open(r'test_cv.jpg', mode='r')\n",
    "im1 = Image.fromarray(sharpened)\n",
    "im1.save('test_cv.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Original Image', remove_noise_and_smooth(cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY))) \n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "[\\[1\\]](https://answers.opencv.org/question/121205/how-to-refine-the-edges-of-an-image/)\n",
    "\n",
    "[\\[2\\]](https://medium.com/cashify-engineering/improve-accuracy-of-ocr-using-image-preprocessing-8df29ec3a033)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
