{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tempfile\n",
    "import imutils\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you gave installed opencv(ver 3.x) package\n",
    "\n",
    "pip install opencv-python imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('test2.jpg', 1)\n",
    "#image = image.astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomendtaions for improving quality of OCR by Tesseracy\n",
    "\n",
    "[soruce](https://tesseract-ocr.github.io/tessdoc/ImproveQuality.html)\n",
    "\n",
    "- [ ] Inverting images\n",
    "- [x] Rescaling tp 300 dpi\n",
    "- [ ] Binarisation [open CV](https://docs.opencv.org/master/d7/d4d/tutorial_py_thresholding.html)\n",
    "- [ ] Noise Removal\n",
    "- [ ] Dilation and Erosion\n",
    "- [ ] Rotation / Deskewing\n",
    "- [ ] Scanning border Removal\n",
    "- [ ] Missing borders\n",
    "\n",
    "---\n",
    "## Page segmentation method\n",
    "\n",
    "By default Tesseract expects a page of text when it segments an image. If you’re just seeking to OCR a small region, try a different segmentation mode, using the --psm argument. Note that adding a white border to text which is too tightly cropped may also help, see issue 398.\n",
    "\n",
    "To see a complete list of supported page segmentation modes, use tesseract -h. Here’s the list as of 3.21:\n",
    "\n",
    "  0    Orientation and script detection (OSD) only.\n",
    "  1    Automatic page segmentation with OSD.\n",
    "  2    Automatic page segmentation, but no OSD, or OCR.\n",
    "  3    Fully automatic page segmentation, but no OSD. (Default)\n",
    "  4    Assume a single column of text of variable sizes.\n",
    "  5    Assume a single uniform block of vertically aligned text.\n",
    "  6    Assume a single uniform block of text.\n",
    "  7    Treat the image as a single text line.\n",
    "  8    Treat the image as a single word.\n",
    "  9    Treat the image as a single word in a circle.\n",
    " 10    Treat the image as a single character.\n",
    " 11    Sparse text. Find as much text as possible in no particular order.\n",
    " 12    Sparse text with OSD.\n",
    " 13    Raw line. Treat the image as a single text line,\n",
    "\t\t\tbypassing hacks that are Tesseract-specific.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_image_dpi(file_path):\n",
    "    im = Image.open(file_path)\n",
    "    length_x, width_y = im.size\n",
    "    factor = min(1, float(1024.0 / length_x))\n",
    "    size = int(factor * length_x), int(factor * width_y)\n",
    "    im_resized = im.resize(size, Image.ANTIALIAS)\n",
    "    temp_file = tempfile.NamedTemporaryFile(delete=False,   suffix='.png')\n",
    "    temp_filename = temp_file.name\n",
    "    im_resized.save(temp_filename, dpi=(300, 300))\n",
    "    return temp_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = set_image_dpi(\"test2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) /io/opencv/modules/imgproc/src/drawing.cpp:2612: error: (-215:Assertion failed) reader.ptr != __null in function 'cvDrawContours'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-ca94aa94d356>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#im1 = Image.open(r'test_cv.jpg', mode='r')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#im1 = Image.fromarray(edged)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mim1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawContours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mscreenCnt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mim1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_cv.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(3.4.2) /io/opencv/modules/imgproc/src/drawing.cpp:2612: error: (-215:Assertion failed) reader.ptr != __null in function 'cvDrawContours'\n"
     ]
    }
   ],
   "source": [
    "# this piece of code works if the text, say, located on the white that lies on the black table\n",
    "# otherwise screenCnt remains None\n",
    "# on the input the colord picture is given\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "edged = cv2.Canny(gray, 10, 50)\n",
    "cnts = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = cnts[0] if imutils.is_cv2() else cnts[1]\n",
    "cnts = sorted(cnts, key=cv2.contourArea, reverse=True)[:5]\n",
    "print(len(cnts))\n",
    "\n",
    "screenCnt = None\n",
    "for c in cnts:\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "    if len(approx) == 4:\n",
    "        screenCnt = approx\n",
    "        print('break')\n",
    "        break\n",
    "\n",
    "#im1 = Image.open(r'test_cv.jpg', mode='r')\n",
    "#im1 = Image.fromarray(edged)\n",
    "im1 = Image.fromarray(cv2.drawContours(image, [screenCnt], -1, (0, 255, 0), 2))\n",
    "im1.save('test_cv.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one batch of funcitons to rotate the image with any rotation\n",
    "\n",
    "def order_points(pts):\n",
    "    # initialzie a list of coordinates that will be ordered\n",
    "    # such that the first entry in the list is the top-left,\n",
    "    # the second entry is the top-right, the third is the\n",
    "    # bottom-right, and the fourth is the bottom-left\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "\n",
    "    # the top-left point will have the smallest sum, whereas\n",
    "    # the bottom-right point will have the largest sum\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "\n",
    "    # now, compute the difference between the points, the\n",
    "    # top-right point will have the smallest difference,\n",
    "    # whereas the bottom-left will have the largest difference\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "\n",
    "    # return the ordered coordinates\n",
    "    return rect\n",
    "\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "    # obtain a consistent order of the points and unpack them\n",
    "    # individually\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "\n",
    "    # compute the width of the new image, which will be the\n",
    "    # maximum distance between bottom-right and bottom-left\n",
    "    # x-coordiates or the top-right and top-left x-coordinates\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    # compute the height of the new image, which will be the\n",
    "    # maximum distance between the top-right and bottom-right\n",
    "    # y-coordinates or the top-left and bottom-left y-coordinates\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "    # now that we have the dimensions of the new image, construct\n",
    "    # the set of destination points to obtain a \"birds eye view\",\n",
    "    # (i.e. top-down view) of the image, again specifying points\n",
    "    # in the top-left, top-right, bottom-right, and bottom-left\n",
    "    # order\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype=\"float32\")\n",
    "\n",
    "    # compute the perspective transform matrix and then apply it\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second approach to rotate an image\n",
    "# doesn't work correctly. Possibly, it works with angels multiples 45 \n",
    "def rotate(img):\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_img = cv2.bitwise_not(gray_img)\n",
    "    coordinates = np.column_stack(np.where(gray_img > 0))\n",
    "    ang = cv2.minAreaRect(coordinates)[-1]\n",
    "    print(ang)\n",
    "    if ang < -45: \n",
    "        ang = -(90 + ang)\n",
    "    else:\n",
    "        ang = -ang\n",
    "    height, width = img.shape[:2]\n",
    "\n",
    "    center_img = (width / 2, height / 2)\n",
    "\n",
    "    rotationMatrix = cv2.getRotationMatrix2D(center_img, ang, 1.0)\n",
    "\n",
    "    rotated_img = cv2.warpAffine(img, rotationMatrix, (width, height), borderMode = cv2.BORDER_REFLECT)\n",
    "    return rotated_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-90.0\n"
     ]
    }
   ],
   "source": [
    "rotated = rotate(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test_cv.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-758e572d4360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mim1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'test_cv.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mim1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrotated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mim1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_cv.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2766\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2767\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_cv.jpg'"
     ]
    }
   ],
   "source": [
    "im1 = Image.open(r'test_cv.jpg', mode='r')\n",
    "im1 = Image.fromarray(rotated)\n",
    "im1.save('test_cv.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise_and_smooth(img):\n",
    "    # input should be grayscale image\n",
    "    filtered = cv2.adaptiveThreshold(img.astype(np.uint8), 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 9, 41)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    opening = cv2.morphologyEx(filtered, cv2.MORPH_OPEN, kernel)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "    # bluring (it can be as you wish. See the doc)\n",
    "    img = cv2.GaussianBlur(img,(3,3),0)\n",
    "    or_image = cv2.bitwise_or(img, closing)\n",
    "    return or_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a3d3a2cb1839>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# rotate image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenCnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mwarped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfour_point_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "# rotate image\n",
    "ratio = 1\n",
    "pts = np.array(screenCnt.reshape(4, 2) * ratio)\n",
    "warped = four_point_transform(image, pts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = Image.open(r'test_cv.jpg', mode='r')\n",
    "im1 = Image.fromarray(warped)\n",
    "im1.save('test_cv.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_noise = remove_noise_and_smooth(cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sharp the image\n",
    "kernel_sharpening = np.array([[-1,-1,-1], \n",
    "                              [-1, 8,-1],\n",
    "                              [-1,-1,-1]])\n",
    "\n",
    "sharpened = cv2.filter2D(smooth, -1, kernel_sharpening)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another sharp (or not)\n",
    "blur = cv2.GaussianBlur(removed_noise,(3,3),0)\n",
    "smooth = cv2.addWeighted(blur,1.5,removed_noise,-0.5,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = Image.open(r'test_cv.jpg', mode='r')\n",
    "im1 = Image.fromarray(sharpened)\n",
    "im1.save('test_cv.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Original Image', remove_noise_and_smooth(cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY))) \n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "[\\[1\\]](https://answers.opencv.org/question/121205/how-to-refine-the-edges-of-an-image/)\n",
    "\n",
    "[\\[2\\]](https://medium.com/cashify-engineering/improve-accuracy-of-ocr-using-image-preprocessing-8df29ec3a033)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[source](https://www.danvk.org/2015/01/07/finding-blocks-of-text-in-an-image-using-python-opencv-and-numpy.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "from scipy.ndimage.filters import rank_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilate(ary, N, iterations): \n",
    "    \"\"\"Dilate using an NxN '+' sign shape. ary is np.uint8.\"\"\"\n",
    "    kernel = np.zeros((N,N), dtype=np.uint8)\n",
    "    \n",
    "    kernel[int((N-1)/2) ,:] = 1\n",
    "    dilated_image = cv2.dilate(ary / 255, kernel, iterations=iterations)\n",
    "\n",
    "    kernel = np.zeros((N,N), dtype=np.uint8)\n",
    "    kernel[:,int((N-1)/2)] = 1\n",
    "    dilated_image = cv2.dilate(dilated_image, kernel, iterations=iterations)\n",
    "    return dilated_image\n",
    "\n",
    "\n",
    "def props_for_contours(contours, ary):\n",
    "    \"\"\"Calculate bounding box & the number of set pixels for each contour.\"\"\"\n",
    "    c_info = []\n",
    "    for c in contours:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        c_im = np.zeros(ary.shape)\n",
    "        cv2.drawContours(c_im, [c], 0, 255, -1)\n",
    "        c_info.append({\n",
    "            'x1': x,\n",
    "            'y1': y,\n",
    "            'x2': x + w - 1,\n",
    "            'y2': y + h - 1,\n",
    "            'sum': np.sum(ary * (c_im > 0))/255\n",
    "        })\n",
    "    return c_info\n",
    "\n",
    "\n",
    "def union_crops(crop1, crop2):\n",
    "    \"\"\"Union two (x1, y1, x2, y2) rects.\"\"\"\n",
    "    x11, y11, x21, y21 = crop1\n",
    "    x12, y12, x22, y22 = crop2\n",
    "    return min(x11, x12), min(y11, y12), max(x21, x22), max(y21, y22)\n",
    "\n",
    "\n",
    "def intersect_crops(crop1, crop2):\n",
    "    x11, y11, x21, y21 = crop1\n",
    "    x12, y12, x22, y22 = crop2\n",
    "    return max(x11, x12), max(y11, y12), min(x21, x22), min(y21, y22)\n",
    "\n",
    "\n",
    "def crop_area(crop):\n",
    "    x1, y1, x2, y2 = crop\n",
    "    return max(0, x2 - x1) * max(0, y2 - y1)\n",
    "\n",
    "\n",
    "def find_border_components(contours, ary):\n",
    "    borders = []\n",
    "    area = ary.shape[0] * ary.shape[1]\n",
    "    for i, c in enumerate(contours):\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        if w * h > 0.5 * area:\n",
    "            borders.append((i, x, y, x + w - 1, y + h - 1))\n",
    "    return borders\n",
    "\n",
    "\n",
    "def angle_from_right(deg):\n",
    "    return min(deg % 90, 90 - (deg % 90))\n",
    "\n",
    "\n",
    "def remove_border(contour, ary):\n",
    "    \"\"\"Remove everything outside a border contour.\"\"\"\n",
    "    # Use a rotated rectangle (should be a good approximation of a border).\n",
    "    # If it's far from a right angle, it's probably two sides of a border and\n",
    "    # we should use the bounding box instead.\n",
    "    c_im = np.zeros(ary.shape)\n",
    "    r = cv2.minAreaRect(contour)\n",
    "    degs = r[2]\n",
    "    if angle_from_right(degs) <= 10.0:\n",
    "        box = cv2.cv.BoxPoints(r)\n",
    "        box = np.int0(box)\n",
    "        cv2.drawContours(c_im, [box], 0, 255, -1)\n",
    "        cv2.drawContours(c_im, [box], 0, 0, 4)\n",
    "    else:\n",
    "        x1, y1, x2, y2 = cv2.boundingRect(contour)\n",
    "        cv2.rectangle(c_im, (x1, y1), (x2, y2), 255, -1)\n",
    "        cv2.rectangle(c_im, (x1, y1), (x2, y2), 0, 4)\n",
    "\n",
    "    return np.minimum(c_im, ary)\n",
    "\n",
    "\n",
    "def find_components(edges, max_components=16):\n",
    "    \"\"\"Dilate the image until there are just a few connected components.\n",
    "    Returns contours for these components.\"\"\"\n",
    "    # Perform increasingly aggressive dilation until there are just a few\n",
    "    # connected components.\n",
    "    count = 21\n",
    "    dilation = 5\n",
    "    n = 1\n",
    "    print('image dtype ',edges.dtype)\n",
    "    while count > 16:\n",
    "        n += 1\n",
    "        dilated_image = dilate(edges, N=3, iterations=n)#.astype(np.uint8)\n",
    "        dilated_image = np.uint8(dilated_image)\n",
    "        _, contours, hierarchy = cv2.findContours(dilated_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        count = len(contours)\n",
    "    #print dilation\n",
    "    #Image.fromarray(edges).show()\n",
    "    #Image.fromarray(255 * dilated_image).show()\n",
    "    return contours\n",
    "\n",
    "\n",
    "def find_optimal_components_subset(contours, edges):\n",
    "    \"\"\"Find a crop which strikes a good balance of coverage/compactness.\n",
    "    Returns an (x1, y1, x2, y2) tuple.\n",
    "    \"\"\"\n",
    "    c_info = props_for_contours(contours, edges)\n",
    "    c_info.sort(key=lambda x: -x['sum'])\n",
    "    total = np.sum(edges) / 255\n",
    "    area = edges.shape[0] * edges.shape[1]\n",
    "\n",
    "    c = c_info[0]\n",
    "    del c_info[0]\n",
    "    this_crop = c['x1'], c['y1'], c['x2'], c['y2']\n",
    "    crop = this_crop\n",
    "    covered_sum = c['sum']\n",
    "\n",
    "    while covered_sum < total:\n",
    "        changed = False\n",
    "        recall = 1.0 * covered_sum / total\n",
    "        prec = 1 - 1.0 * crop_area(crop) / area\n",
    "        f1 = 2 * (prec * recall / (prec + recall))\n",
    "        #print '----'\n",
    "        for i, c in enumerate(c_info):\n",
    "            this_crop = c['x1'], c['y1'], c['x2'], c['y2']\n",
    "            new_crop = union_crops(crop, this_crop)\n",
    "            new_sum = covered_sum + c['sum']\n",
    "            new_recall = 1.0 * new_sum / total\n",
    "            new_prec = 1 - 1.0 * crop_area(new_crop) / area\n",
    "            new_f1 = 2 * new_prec * new_recall / (new_prec + new_recall)\n",
    "\n",
    "            # Add this crop if it improves f1 score,\n",
    "            # _or_ it adds 25% of the remaining pixels for <15% crop expansion.\n",
    "            # ^^^ very ad-hoc! make this smoother\n",
    "            remaining_frac = c['sum'] / (total - covered_sum)\n",
    "            new_area_frac = 1.0 * crop_area(new_crop) / crop_area(crop) - 1\n",
    "            if new_f1 > f1 or (\n",
    "                    remaining_frac > 0.25 and new_area_frac < 0.15):\n",
    "                print('%d %s -> %s / %s (%s), %s -> %s / %s (%s), %s -> %s' % (\n",
    "                        i, covered_sum, new_sum, total, remaining_frac,\n",
    "                        crop_area(crop), crop_area(new_crop), area, new_area_frac,\n",
    "                        f1, new_f1))\n",
    "                crop = new_crop\n",
    "                covered_sum = new_sum\n",
    "                del c_info[i]\n",
    "                changed = True\n",
    "                break\n",
    "\n",
    "        if not changed:\n",
    "            break\n",
    "\n",
    "    return crop\n",
    "\n",
    "\n",
    "def pad_crop(crop, contours, edges, border_contour, pad_px=15):\n",
    "    \"\"\"Slightly expand the crop to get full contours.\n",
    "    This will expand to include any contours it currently intersects, but will\n",
    "    not expand past a border.\n",
    "    \"\"\"\n",
    "    bx1, by1, bx2, by2 = 0, 0, edges.shape[0], edges.shape[1]\n",
    "    if border_contour is not None and len(border_contour) > 0:\n",
    "        c = props_for_contours([border_contour], edges)[0]\n",
    "        bx1, by1, bx2, by2 = c['x1'] + 5, c['y1'] + 5, c['x2'] - 5, c['y2'] - 5\n",
    "\n",
    "    def crop_in_border(crop):\n",
    "        x1, y1, x2, y2 = crop\n",
    "        x1 = max(x1 - pad_px, bx1)\n",
    "        y1 = max(y1 - pad_px, by1)\n",
    "        x2 = min(x2 + pad_px, bx2)\n",
    "        y2 = min(y2 + pad_px, by2)\n",
    "        return crop\n",
    "    \n",
    "    crop = crop_in_border(crop)\n",
    "\n",
    "    c_info = props_for_contours(contours, edges)\n",
    "    changed = False\n",
    "    for c in c_info:\n",
    "        this_crop = c['x1'], c['y1'], c['x2'], c['y2']\n",
    "        this_area = crop_area(this_crop)\n",
    "        int_area = crop_area(intersect_crops(crop, this_crop))\n",
    "        new_crop = crop_in_border(union_crops(crop, this_crop))\n",
    "        if 0 < int_area < this_area and crop != new_crop:\n",
    "            print( '%s -> %s' % (str(crop), str(new_crop)))\n",
    "            changed = True\n",
    "            crop = new_crop\n",
    "\n",
    "    if changed:\n",
    "        return pad_crop(crop, contours, edges, border_contour, pad_px)\n",
    "    else:\n",
    "        return crop\n",
    "\n",
    "\n",
    "def downscale_image(im, max_dim=2048):\n",
    "    \"\"\"Shrink im until its longest dimension is <= max_dim.\n",
    "    Returns new_image, scale (where scale <= 1).\n",
    "    \"\"\"\n",
    "    a, b = im.size\n",
    "    if max(a, b) <= max_dim:\n",
    "        return 1.0, im\n",
    "\n",
    "    scale = 1.0 * max_dim / max(a, b)\n",
    "    new_im = im.resize((int(a * scale), int(b * scale)), Image.ANTIALIAS)\n",
    "    return scale, new_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_image_dpi(im):\n",
    "    length_x, width_y = im.size\n",
    "    factor = min(1, float(1024.0 / length_x))\n",
    "    size = int(factor * length_x), int(factor * width_y)\n",
    "    im_resized = im.resize(size, Image.ANTIALIAS)\n",
    "    return im_resized\n",
    "    #temp_file = tempfile.NamedTemporaryFile(delete=False,   suffix='.png')\n",
    "    #temp_filename = temp_file.name\n",
    "    #im_resized.save(temp_filename, dpi=(300, 300))\n",
    "    #return temp_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-f21c60579eb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mout_path\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"test.crop.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0morig_im\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#orig_im = set_image_dpi(orig_im)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownscale_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2766\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2767\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test.jpg'"
     ]
    }
   ],
   "source": [
    "#def process_image(path, out_path):\n",
    "path = \"test.jpg\"\n",
    "out_path= \"test.crop.jpg\"\n",
    "\n",
    "orig_im = Image.open(path)\n",
    "#orig_im = set_image_dpi(orig_im)\n",
    "scale, im = downscale_image(orig_im)\n",
    "#convolve the image with gaussian blur for Canny\n",
    "#im_blured = cv2.GaussianBlur(np.asarray(im), (5, 5), 0)\n",
    "edges = cv2.Canny(im_blured, 100, 200)\n",
    "\n",
    "# TODO: dilate image _before_ finding a border. This is crazy sensitive!\n",
    "_, contours, hierarchy = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "borders = find_border_components(contours, edges)\n",
    "print(\"OK\")\n",
    "borders.sort(key=lambda i, x1, y1, x2, y2: (x2 - x1) * (y2 - y1))\n",
    "print(\"OK\")\n",
    "border_contour = None\n",
    "if len(borders):\n",
    "    border_contour = contours[borders[0][0]]\n",
    "    edges = remove_border(border_contour, edges)\n",
    "\n",
    "edges = 255 * (edges > 0).astype(np.uint8)\n",
    "\n",
    "# Remove ~1px borders using a rank filter.\n",
    "maxed_rows = rank_filter(edges, -4, size=(1, 20))\n",
    "maxed_cols = rank_filter(edges, -4, size=(20, 1))\n",
    "debordered = np.minimum(np.minimum(edges, maxed_rows), maxed_cols)\n",
    "edges = debordered.astype(np.int32)\n",
    "print(edges.shape)\n",
    "\n",
    "contours = find_components(edges)\n",
    "if len(contours) == 0:\n",
    "    print('%s -> (no text!)' % path)\n",
    "    #return\n",
    "\n",
    "crop = find_optimal_components_subset(contours, edges)\n",
    "crop = pad_crop(crop, contours, edges, border_contour)\n",
    "\n",
    "crop = [int(x / scale) for x in crop]  # upscale to the original image size.\n",
    "#show borders\n",
    "draw = ImageDraw.Draw(im)\n",
    "c_info = props_for_contours(contours, edges)\n",
    "\"\"\"\n",
    "for c in c_info:\n",
    "    this_crop = c['x1'], c['y1'], c['x2'], c['y2']\n",
    "    draw.rectangle(this_crop, outline='blue')\n",
    "draw.rectangle(crop, outline='red')\n",
    "im.save(out_path)\n",
    "draw.text((50, 50), path, fill='red')\n",
    "orig_im.save(out_path)\n",
    "im.show()\n",
    "text_im = orig_im.crop(crop)\n",
    "text_im.save(out_path)\n",
    "print('%s -> %s' % (path, out_path))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACEAAAAcCAIAAABgYkFLAAAAGUlEQVR4nO3BAQ0AAADCoPdPbQ8HFAAA/BoK8AAB/4iNfAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=33x28 at 0x7F135FA63AD0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "croped_im.crop((c_info[i]['x1'], c_info[i]['y1'],c_info[i]['x2'], c_info[i]['y2'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "croped_im.save(out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
